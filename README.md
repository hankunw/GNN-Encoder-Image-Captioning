# GNN-Encoder-Image-Captioning
## The dataset I used in this project are: flicker8k (https://www.kaggle.com/datasets/adityajn105/flickr8k) and COCO 2014 val image captioning dataset (https://www.kaggle.com/datasets/nikhil7280/coco-image-caption)
## Model checkpoints for flicker8k test experiments and generalization experiments are all included in model_checkpoints folder
